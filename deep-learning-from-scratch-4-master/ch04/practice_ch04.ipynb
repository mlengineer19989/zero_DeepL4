{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反復方策評価を試す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L1': -2.249167525908671, 'L2': -2.749167525908671}\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "V = {'L1': 0.0, 'L2': 0.0}\n",
    "new_V = V.copy()\n",
    "\n",
    "cnt = 0\n",
    "while True:\n",
    "    new_V['L1'] = 0.5 * (-1 + 0.9 * V['L1']) + 0.5 * (1 + 0.9 * V['L2'])\n",
    "    new_V['L2'] = 0.5 * (0 + 0.9 * V['L1']) + 0.5 * (-1 + 0.9 * V['L2'])\n",
    "\n",
    "    delta = abs(new_V['L1'] - V['L1'])\n",
    "    delta = max(delta, abs(new_V['L2'] - V['L2']))\n",
    "    V = new_V.copy()\n",
    "\n",
    "    cnt += 1\n",
    "    if delta < 0.0001:\n",
    "        print(V)\n",
    "        print(cnt)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 反復方策評価の別の実装方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L1': -2.2493782177156936, 'L2': -2.7494201578106514}\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "V = {'L1': 0.0, 'L2': 0.0}\n",
    "\n",
    "cnt = 0\n",
    "while True:\n",
    "    t = 0.5 * (-1 + 0.9 * V['L1']) + 0.5 * (1 + 0.9 * V['L2'])\n",
    "    delta = abs(t - V['L1'])\n",
    "    V['L1'] = t\n",
    "\n",
    "    t = 0.5 * (0 + 0.9 * V['L1']) + 0.5 * (-1 + 0.9 * V['L2'])\n",
    "    delta = max(delta, abs(t - V['L2']))\n",
    "    V['L2'] = t\n",
    "\n",
    "    cnt += 1\n",
    "    if delta < 0.0001:\n",
    "        print(V)\n",
    "        print(cnt)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridWorldクラスの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "import common.gridworld_render as render_helper\n",
    "\n",
    "class GridWorld:\n",
    "    def __init__(self):\n",
    "        self.action_space = [0, 1, 2, 3]\n",
    "        self.action_meaning = {\n",
    "            0: \"UP\",\n",
    "            1: \"DOWN\",\n",
    "            2: \"LEFT\",\n",
    "            3: \"RIGHT\",\n",
    "        }\n",
    "\n",
    "        self.reward_map = np.array(\n",
    "            [[0, 0, 0, 1.0],\n",
    "             [0, None, 0, -1.0],\n",
    "             [0, 0, 0, 0]]\n",
    "        )\n",
    "        self.goal_state = (0, 3)\n",
    "        self.wall_state = (1, 1)\n",
    "        self.start_state = (2, 0)\n",
    "        self.agent_state = self.start_state\n",
    "\n",
    "    @property\n",
    "    def height(self):\n",
    "        return len(self.reward_map)\n",
    "\n",
    "    @property\n",
    "    def width(self):\n",
    "        return len(self.reward_map[0])\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        return self.reward_map.shape\n",
    "\n",
    "    def actions(self):\n",
    "        return self.action_space\n",
    "\n",
    "    def states(self):\n",
    "        for h in range(self.height):\n",
    "            for w in range(self.width):\n",
    "                yield (h, w)\n",
    "\n",
    "    def next_state(self, state, action):\n",
    "        #移動先の場所の計算①\n",
    "        action_move_map = [(-1, 0), (1, 0), (0, -1), (0, 1)]\n",
    "        move = action_move_map[action]\n",
    "        next_state = (state[0] + move[0], state[1] + move[1])\n",
    "        ny, nx = next_state\n",
    "\n",
    "        #移動先がグリッドワールドの枠の外か、\n",
    "        if nx < 0 or nx >= self.width or ny < 0 or ny >= self.height:\n",
    "            next_state = state\n",
    "        elif next_state == self.wall_state:\n",
    "            next_state = state\n",
    "\n",
    "        return next_state\n",
    "\n",
    "    def reward(self, state, action, next_state):\n",
    "        return self.reward_map[next_state]\n",
    "\n",
    "    def render_v(self, v=None, policy=None, print_value=True):\n",
    "        renderer = render_helper.Renderer(self.reward_map, self.goal_state,\n",
    "                                            self.wall_state)\n",
    "        renderer.render_v(v, policy, print_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "131890dab21eae7250f658285fc23dc32d54d8a0c5b6241dfc540553a94bd1eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
